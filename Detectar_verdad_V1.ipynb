{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo NLP para detección de la veracidad o no de mensajes del juego DIPLOMACY mediante XLNet-model\n",
    "Modelo de predicción a partir de cadena de caracteres que indica si la frase es verdadera o falsa, utilizando el modelo pre-entrenado XLNet.\n",
    "https://huggingface.co/docs/transformers/model_doc/xlnet\n",
    "\n",
    "28ENE2024 Jhon A. Monsalve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josef\\AppData\\Local\\Temp\\ipykernel_13264\\337587528.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deception in Diplomacy Dataset\n",
    "Dataset with intended and perceived deception labels in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Over 17,000 messages are annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. This dataset captures deception in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives\n",
    "\n",
    "Distributed together with: It Takes Two to Lie: One to Lie, and One to Listen. Denis Peskov, Benny Cheng, Ahmed Elgohary, Joe Barrow, Cristian Danescu-Niculescu-Mizil and Jordan Boyd-Graber. Proceedings of ACL 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\josef\\.convokit\\downloads\\diplomacy-corpus\n"
     ]
    }
   ],
   "source": [
    "# Descargar los datos historicos de DIPLOMACY desde ConvoKit\n",
    "# !pip install convokit\n",
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"diplomacy-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 83\n",
      "Number of Utterances: 17289\n",
      "Number of Conversations: 246\n"
     ]
    }
   ],
   "source": [
    "# Estadisticas de la fuente de datos\n",
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\josef\\.convokit\\downloads\\diplomacy-corpus\n",
      "Number of Speakers: 62\n",
      "Number of Utterances: 13132\n",
      "Number of Conversations: 184\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "corpus_train = Corpus(filename=download(\"diplomacy-corpus\"))\n",
    "corpus_train.filter_conversations_by(lambda convo: convo.meta.get('acl2020_fold')=='Train')\n",
    "corpus_train.print_summary_stats()                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\josef\\.convokit\\downloads\\diplomacy-corpus\n",
      "Number of Speakers: 14\n",
      "Number of Utterances: 2741\n",
      "Number of Conversations: 42\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "corpus_test = Corpus(filename=download(\"diplomacy-corpus\"))\n",
    "corpus_test.filter_conversations_by(lambda convo: convo.meta.get('acl2020_fold')=='Test')\n",
    "corpus_test.print_summary_stats()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\josef\\.convokit\\downloads\\diplomacy-corpus\n",
      "Number of Speakers: 7\n",
      "Number of Utterances: 1416\n",
      "Number of Conversations: 20\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "corpus_validation = Corpus(filename=download(\"diplomacy-corpus\"))\n",
    "corpus_validation.filter_conversations_by(lambda convo: convo.meta.get('acl2020_fold')=='Validation')\n",
    "corpus_validation.print_summary_stats()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>root</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>meta</th>\n",
       "      <th>reply-to</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speaker_intention</th>\n",
       "      <th>receiver_perception</th>\n",
       "      <th>receiver</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>year</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>deception_quadrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17286</th>\n",
       "      <td>Game9-turkey-france-31</td>\n",
       "      <td>Game9-turkey-france</td>\n",
       "      <td>you have anything else in mind?</td>\n",
       "      <td>turkey-Game9</td>\n",
       "      <td>{'speaker_intention': 'Truth', 'receiver_perce...</td>\n",
       "      <td>Game9-turkey-france-30</td>\n",
       "      <td>1369</td>\n",
       "      <td>Truth</td>\n",
       "      <td>Truth</td>\n",
       "      <td>france-Game9</td>\n",
       "      <td>1369</td>\n",
       "      <td>31</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Straightforward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17287</th>\n",
       "      <td>Game9-turkey-france-32</td>\n",
       "      <td>Game9-turkey-france</td>\n",
       "      <td>I guess I'd also be happy to support you into ...</td>\n",
       "      <td>turkey-Game9</td>\n",
       "      <td>{'speaker_intention': 'Truth', 'receiver_perce...</td>\n",
       "      <td>Game9-turkey-france-31</td>\n",
       "      <td>1370</td>\n",
       "      <td>Truth</td>\n",
       "      <td>Truth</td>\n",
       "      <td>france-Game9</td>\n",
       "      <td>1370</td>\n",
       "      <td>32</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Straightforward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17288</th>\n",
       "      <td>Game9-turkey-france-33</td>\n",
       "      <td>Game9-turkey-france</td>\n",
       "      <td>That would be interesting, but I think I want ...</td>\n",
       "      <td>france-Game9</td>\n",
       "      <td>{'speaker_intention': 'Truth', 'receiver_perce...</td>\n",
       "      <td>Game9-turkey-france-32</td>\n",
       "      <td>1385</td>\n",
       "      <td>Truth</td>\n",
       "      <td>None</td>\n",
       "      <td>turkey-Game9</td>\n",
       "      <td>1385</td>\n",
       "      <td>33</td>\n",
       "      <td>1903</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id                 root  \\\n",
       "17286  Game9-turkey-france-31  Game9-turkey-france   \n",
       "17287  Game9-turkey-france-32  Game9-turkey-france   \n",
       "17288  Game9-turkey-france-33  Game9-turkey-france   \n",
       "\n",
       "                                                    text       speaker  \\\n",
       "17286                    you have anything else in mind?  turkey-Game9   \n",
       "17287  I guess I'd also be happy to support you into ...  turkey-Game9   \n",
       "17288  That would be interesting, but I think I want ...  france-Game9   \n",
       "\n",
       "                                                    meta  \\\n",
       "17286  {'speaker_intention': 'Truth', 'receiver_perce...   \n",
       "17287  {'speaker_intention': 'Truth', 'receiver_perce...   \n",
       "17288  {'speaker_intention': 'Truth', 'receiver_perce...   \n",
       "\n",
       "                     reply-to  timestamp speaker_intention  \\\n",
       "17286  Game9-turkey-france-30       1369             Truth   \n",
       "17287  Game9-turkey-france-31       1370             Truth   \n",
       "17288  Game9-turkey-france-32       1385             Truth   \n",
       "\n",
       "      receiver_perception      receiver  absolute_message_index  \\\n",
       "17286               Truth  france-Game9                    1369   \n",
       "17287               Truth  france-Game9                    1370   \n",
       "17288                None  turkey-Game9                    1385   \n",
       "\n",
       "       relative_message_index  year game_score game_score_delta  \\\n",
       "17286                      31  1903          4               -1   \n",
       "17287                      32  1903          4               -1   \n",
       "17288                      33  1903          5                1   \n",
       "\n",
       "      deception_quadrant  \n",
       "17286    Straightforward  \n",
       "17287    Straightforward  \n",
       "17288            Unknown  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos desde el archivo utterances.jsonl que contiene las interacciones totales de la fuente corpus\n",
    "json = './data/utterances.jsonl'\n",
    "\n",
    "df = pd.read_json(json, lines=True) # Cargar el archivo JSONL en un DataFrame de Pandas\n",
    "\n",
    "# 'meta' contiene cadenas JSON y se desea expandir en columnas\n",
    "if 'meta' in df.columns:\n",
    "    # Convertir las cadenas JSON en columnas separadas\n",
    "    df_json = df['meta'].apply(pd.Series)\n",
    "\n",
    "    # Concatenar las nuevas columnas al DataFrame original\n",
    "    dataframe = pd.concat([df, df_json], axis=1)\n",
    "\n",
    "dataframe.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"./output/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texto        object\n",
       "respuesta     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar las columnas que aplican al modelo\n",
    "df= dataframe.drop(['id','root','speaker','meta','reply-to','timestamp','receiver_perception','receiver','absolute_message_index',\n",
    "                'relative_message_index','year','game_score','game_score_delta','deception_quadrant'], axis = 'columns')\n",
    "\n",
    "# reemplazar el speaker_intention de \"Lie\" a 0 y \"Truth\" a 1 como valores numericos para el modelo\n",
    "df.speaker_intention = df.speaker_intention.replace(\"Lie\",0).replace(\"Truth\",1)\n",
    "df = df.rename(columns={ 'text':'texto','speaker_intention':'respuesta' })\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dividir datos (entrenamiento, prueba y validación según muestras originales)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y conjunto temporal (80% entrenamiento, 20% temporal)\n",
    "df_entrenamiento, df_temporal = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir el conjunto temporal en conjunto de prueba y conjunto de validación (50% cada uno)\n",
    "df_prueba, df_validacion = train_test_split(df_temporal, test_size=0.5, random_state=42)\n",
    "\n",
    "# df_entrenamiento contiene el 80% de los datos originales, df_prueba contiene el 10%, y df_validacion contiene el 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO XLNet\n",
    "Modelo preentrenado que utiliza una arquitectura de transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, AdamW\n",
    "import torch.nn.functional as F\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb18bb2e2bb43148d39b32bb3802fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc98c355fe942cfb3b254a97a7ff570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3c7741d73449eb9f7f996051eebe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37477a97ba2542c0a81dd4f16afaddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el tokenizador y el modelo XLNet preentrenado para clasificación de secuencias\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar los textos\n",
    "inputs = tokenizer(df['texto'].tolist(), padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un TensorDataset\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], torch.tensor(df['respuesta'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba [80-20]\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataLoader para facilitar el entrenamiento\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el modelo para entrenar\n",
    "model.train()\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, labels)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "for epoch in range(2):  # Número de veces que pasa por el conjunto de entrenamiento\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        total_correct += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No logré llegar a esta última etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
